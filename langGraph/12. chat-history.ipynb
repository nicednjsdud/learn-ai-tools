{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ddgs in e:\\jwy\\learn-ai-tools\\venv_llm\\lib\\site-packages (9.10.0)\n",
      "Requirement already satisfied: click>=8.1.8 in e:\\jwy\\learn-ai-tools\\venv_llm\\lib\\site-packages (from ddgs) (8.3.1)\n",
      "Requirement already satisfied: primp>=0.15.0 in e:\\jwy\\learn-ai-tools\\venv_llm\\lib\\site-packages (from ddgs) (0.15.0)\n",
      "Requirement already satisfied: lxml>=4.9.4 in e:\\jwy\\learn-ai-tools\\venv_llm\\lib\\site-packages (from ddgs) (6.0.2)\n",
      "Requirement already satisfied: httpx>=0.28.1 in e:\\jwy\\learn-ai-tools\\venv_llm\\lib\\site-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.28.1)\n",
      "Requirement already satisfied: fake-useragent>=2.2.0 in e:\\jwy\\learn-ai-tools\\venv_llm\\lib\\site-packages (from ddgs) (2.2.0)\n",
      "Requirement already satisfied: colorama in e:\\jwy\\learn-ai-tools\\venv_llm\\lib\\site-packages (from click>=8.1.8->ddgs) (0.4.6)\n",
      "Requirement already satisfied: anyio in e:\\jwy\\learn-ai-tools\\venv_llm\\lib\\site-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.12.0)\n",
      "Requirement already satisfied: certifi in e:\\jwy\\learn-ai-tools\\venv_llm\\lib\\site-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\jwy\\learn-ai-tools\\venv_llm\\lib\\site-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.9)\n",
      "Requirement already satisfied: idna in e:\\jwy\\learn-ai-tools\\venv_llm\\lib\\site-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in e:\\jwy\\learn-ai-tools\\venv_llm\\lib\\site-packages (from httpcore==1.*->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.16.0)\n",
      "Requirement already satisfied: brotli in e:\\jwy\\learn-ai-tools\\venv_llm\\lib\\site-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.2.0)\n",
      "Requirement already satisfied: h2<5,>=3 in e:\\jwy\\learn-ai-tools\\venv_llm\\lib\\site-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.3.0)\n",
      "Requirement already satisfied: socksio==1.* in e:\\jwy\\learn-ai-tools\\venv_llm\\lib\\site-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in e:\\jwy\\learn-ai-tools\\venv_llm\\lib\\site-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in e:\\jwy\\learn-ai-tools\\venv_llm\\lib\\site-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in e:\\jwy\\learn-ai-tools\\venv_llm\\lib\\site-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U ddgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU \"langchain-google-community[gmail]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet langchain-community arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "small_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search_tool = DuckDuckGoSearchRun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jo\\AppData\\Local\\Temp\\ipykernel_35216\\523952650.py:13: DeprecationWarning: get_gmail_credentials is deprecated and will be removed in a future version.Use get_google_credentials instead.\n",
      "  credentials = get_gmail_credentials(\n",
      "C:\\Users\\jo\\AppData\\Local\\Temp\\ipykernel_35216\\523952650.py:19: DeprecationWarning: build_resource_service is deprecated and will be removed in a future version.Use build_gmail_service instead.\n",
      "  api_resource = build_resource_service(credentials=credentials)\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_community import GmailToolkit\n",
    "from langchain_google_community.gmail.utils import (\n",
    "  build_resource_service,\n",
    "  get_gmail_credentials\n",
    ")\n",
    "\n",
    "SCOPES = [\n",
    "    \"https://www.googleapis.com/auth/gmail.readonly\",\n",
    "    \"https://www.googleapis.com/auth/gmail.compose\",\n",
    "    \"https://www.googleapis.com/auth/gmail.send\",\n",
    "]\n",
    "\n",
    "credentials = get_gmail_credentials(\n",
    "    token_file=\"./google/gmail_token.json\",\n",
    "    scopes=SCOPES,\n",
    "    client_sercret_file=\"./google/gmail_credentials.json\",\n",
    ")\n",
    "\n",
    "api_resource = build_resource_service(credentials=credentials)\n",
    "gmail_toolKit = GmailToolkit(api_resource=api_resource)\n",
    "gmail_tool_list = gmail_toolKit.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits.load_tools import load_tools\n",
    "\n",
    "loaded_tool_list = load_tools(\n",
    "  [\"arxiv\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "\n",
    "embedding_function = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vector_store = Chroma(\n",
    "  embedding_function=embedding_function,\n",
    "  collection_name=\"real_estate_tax\",\n",
    "  persist_directory=\"./chroma_db\"  # ✅ 디렉터리\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "retriever_tool = create_retriever_tool(\n",
    "  retriever=retriever,\n",
    "  name='real_estate_tax_retriever',\n",
    "  description='Useful for answering questions about real estate tax in South Korea.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tool_list = [add, multiply, search_tool, retriever_tool] + gmail_tool_list + loaded_tool_list\n",
    "llm_with_tools = llm.bind_tools(tool_list)\n",
    "tool_node = ToolNode(tool_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "class AgentState(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "graph_builder = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "def agent(state: AgentState) :\n",
    "    messages = state['messages']\n",
    "    summary = state['summary']\n",
    "    if summary != '':\n",
    "        messages = [SystemMessage(content=f'Here is the summary of previous conversation: {summary}')] + messages\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {'messages' : [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_messages(state : AgentState):\n",
    "    messages = state['messages']\n",
    "    summary = state['summary']\n",
    "    summary_prompt = f'summarize this chat history below: \\n\\nchat_history:{messages}'\n",
    "    if summary != '':\n",
    "        summary_prompt = f'''summarize this chat history below while looking at the summary of earlier conversations\n",
    "    chat_history:{messages}\n",
    "    summary : {summary}\n",
    "    ''' \n",
    "\n",
    "    summary = small_llm.invoke(summary_prompt)\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {'summary' : response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import RemoveMessage\n",
    "\n",
    "def delete_messages(state : AgentState):\n",
    "  messages = state['messages']\n",
    "  delete_message = [RemoveMessage(id=message.id) for message in messages[:-3]]\n",
    "  return {'messages' : delete_message}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "\n",
    "def should_continue(state : AgentState):\n",
    "    message = state['messages']\n",
    "    last_ai_message = message[-1]\n",
    "    if last_ai_message.tool_calls:\n",
    "        return 'tools'\n",
    "    return 'summarize_messages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x182a8759690>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_node('agent', agent)\n",
    "graph_builder.add_node('tools', tool_node)\n",
    "graph_builder.add_node(delete_messages)\n",
    "graph_builder.add_node(summarize_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x182a8759690>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import START, END\n",
    "graph_builder.add_edge(START, 'agent')\n",
    "graph_builder.add_conditional_edges(\n",
    "  'agent',\n",
    "   should_continue,\n",
    "   ['tools', 'summarize_messages']\n",
    ")\n",
    "graph_builder.add_edge('tools', 'agent')\n",
    "graph_builder.add_edge('summarize_messages', 'delete_messages')\n",
    "graph_builder.add_edge('delete_messages', END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "checkPointer = MemorySaver()\n",
    "\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=checkPointer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "png_bytes = graph.get_graph().draw_mermaid_png()\n",
    "display(Image(data=png_bytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "nicednjsdud@gmail.com으로 Attention Is All You Need 논문을 요약해서 이메일 초안을 작성해주세요.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  arxiv (call_U1XC429NSneXP69DMZS3c3yr)\n",
      " Call ID: call_U1XC429NSneXP69DMZS3c3yr\n",
      "  Args:\n",
      "    query: Attention Is All You Need\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: arxiv\n",
      "\n",
      "Published: 2021-05-06\n",
      "Title: Do You Even Need Attention? A Stack of Feed-Forward Layers Does Surprisingly Well on ImageNet\n",
      "Authors: Luke Melas-Kyriazi\n",
      "Summary: The strong performance of vision transformers on image classification and other vision tasks is often attributed to the design of their multi-head attention layers. However, the extent to which attention is responsible for this strong performance remains unclear. In this short report, we ask: is the attention layer even necessary? Specifically, we replace the attention layer in a vision transformer with a feed-forward layer applied over the patch dimension. The resulting architecture is simply a series of feed-forward layers applied over the patch and feature dimensions in an alternating fashion. In experiments on ImageNet, this architecture performs surprisingly well: a ViT/DeiT-base-sized model obtains 74.9\\% top-1 accuracy, compared to 77.9\\% and 79.9\\% for ViT and DeiT respectively. These results indicate that aspects of vision transformers other than attention, such as the patch embedding, may be more responsible for their strong performance than previously thought. We hope these results prompt the community to spend more time trying to understand why our current models are as effective as they are.\n",
      "\n",
      "Published: 2025-12-03\n",
      "Title: \"All You Need\" is Not All You Need for a Paper Title: On the Origins of a Scientific Meme\n",
      "Authors: Anton Alyakin\n",
      "Summary: The 2017 paper ''Attention Is All You Need'' introduced the Transformer architecture-and inadvertently spawned one of machine learning's most persistent naming conventions. We analyze 717 arXiv preprints containing ''All You Need'' in their titles (2009-2025), finding exponential growth ($R^2$ > 0.994) following the original paper, with 200 titles in 2025 alone. Among papers following the canonical ''X [Is] All You Need'' structure, ''Attention'' remains the most frequently claimed necessity (28 occurrences). Situating this phenomenon within memetic theory, we argue the pattern's success reflects competitive pressures in scientific communication that increasingly favor memorability over precision. Whether this trend represents harmless academic whimsy or symptomatic sensationalism, we leave-with appropriate self-awareness-to the reader.\n",
      "\n",
      "Published: 2018-06-28\n",
      "Title: Quit When You Can: Efficient Evaluation of Ensembles with Ordering Optimization\n",
      "Authors: Serena Wang, Maya Gupta, Seungil You\n",
      "Summary: Given a classifier ensemble and a set of examples to be classified, many examples may be confidently and accurately classified after only a subset of the base models in the ensemble are evaluated. This can reduce both mean latency and CPU while maintaining the high accuracy of the original ensemble. To achieve such gains, we propose jointly optimizing a fixed evaluation order of the base models and early-stopping thresholds. Our proposed objective is a combinatorial optimization problem, but we provide a greedy algorithm that achieves a 4-approximation of the optimal solution for certain cases. For those cases, this is also the best achievable polynomial time approximation bound unless $P = NP$. Experiments on benchmark and real-world problems show that the proposed Quit When You Can (QWYC) algorithm can speed-up average evaluation time by $2$x--$4$x, and is around $1.5$x faster than prior work. QWYC's joint optimization of ordering and thresholds also performed better in experiments than various fixed orderings, including gradient boosted trees' ordering.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  arxiv (call_iQdajb3D2b4hLLE1ooJUD6ND)\n",
      " Call ID: call_iQdajb3D2b4hLLE1ooJUD6ND\n",
      "  Args:\n",
      "    query: Attention Is All You Need paper\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: arxiv\n",
      "\n",
      "Published: 2006-01-22\n",
      "Title: This paper has been withdrawn\n",
      "Authors: This paper has been withdrawn\n",
      "Summary: This paper has been withdrawn\n",
      "\n",
      "Published: 2025-12-03\n",
      "Title: \"All You Need\" is Not All You Need for a Paper Title: On the Origins of a Scientific Meme\n",
      "Authors: Anton Alyakin\n",
      "Summary: The 2017 paper ''Attention Is All You Need'' introduced the Transformer architecture-and inadvertently spawned one of machine learning's most persistent naming conventions. We analyze 717 arXiv preprints containing ''All You Need'' in their titles (2009-2025), finding exponential growth ($R^2$ > 0.994) following the original paper, with 200 titles in 2025 alone. Among papers following the canonical ''X [Is] All You Need'' structure, ''Attention'' remains the most frequently claimed necessity (28 occurrences). Situating this phenomenon within memetic theory, we argue the pattern's success reflects competitive pressures in scientific communication that increasingly favor memorability over precision. Whether this trend represents harmless academic whimsy or symptomatic sensationalism, we leave-with appropriate self-awareness-to the reader.\n",
      "\n",
      "Published: 2021-05-06\n",
      "Title: Do You Even Need Attention? A Stack of Feed-Forward Layers Does Surprisingly Well on ImageNet\n",
      "Authors: Luke Melas-Kyriazi\n",
      "Summary: The strong performance of vision transformers on image classification and other vision tasks is often attributed to the design of their multi-head attention layers. However, the extent to which attention is responsible for this strong performance remains unclear. In this short report, we ask: is the attention layer even necessary? Specifically, we replace the attention layer in a vision transformer with a feed-forward layer applied over the patch dimension. The resulting architecture is simply a series of feed-forward layers applied over the patch and feature dimensions in an alternating fashion. In experiments on ImageNet, this architecture performs surprisingly well: a ViT/DeiT-base-sized model obtains 74.9\\% top-1 accuracy, compared to 77.9\\% and 79.9\\% for ViT and DeiT respectively. These results indicate that aspects of vision transformers other than attention, such as the patch embedding, may be more responsible for their strong performance than previously thought. We hope these results prompt the community to spend more time trying to understand why our current models are as effective as they are.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I couldn't find the specific summary for the \"Attention Is All You Need\" paper. However, I can provide a general summary based on my knowledge:\n",
      "\n",
      "The \"Attention Is All You Need\" paper introduces the Transformer model, which is a novel architecture for sequence transduction tasks. The key innovation of the Transformer is the use of self-attention mechanisms, which allow the model to weigh the importance of different words in a sentence when encoding and decoding sequences. This approach eliminates the need for recurrent layers, making the model more parallelizable and efficient. The Transformer has been highly influential, leading to significant advancements in natural language processing tasks.\n",
      "\n",
      "Now, I will create an email draft with this summary.\n",
      "Tool Calls:\n",
      "  create_gmail_draft (call_ncuaYx3BfAvzBU0uQKdMTjpl)\n",
      " Call ID: call_ncuaYx3BfAvzBU0uQKdMTjpl\n",
      "  Args:\n",
      "    message: The \"Attention Is All You Need\" paper introduces the Transformer model, which is a novel architecture for sequence transduction tasks. The key innovation of the Transformer is the use of self-attention mechanisms, which allow the model to weigh the importance of different words in a sentence when encoding and decoding sequences. This approach eliminates the need for recurrent layers, making the model more parallelizable and efficient. The Transformer has been highly influential, leading to significant advancements in natural language processing tasks.\n",
      "    to: ['nicednjsdud@gmail.com']\n",
      "    subject: Summary of 'Attention Is All You Need' Paper\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: create_gmail_draft\n",
      "\n",
      "Draft created. Draft Id: r-5053400065641278795\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I have created an email draft summarizing the \"Attention Is All You Need\" paper. You can find it in your drafts folder with the subject \"Summary of 'Attention Is All You Need' Paper.\"\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I have created an email draft summarizing the \"Attention Is All You Need\" paper. You can find it in your drafts folder with the subject \"Summary of 'Attention Is All You Need' Paper.\"\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I have created an email draft summarizing the \"Attention Is All You Need\" paper. You can find it in your drafts folder with the subject \"Summary of 'Attention Is All You Need' Paper.\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "config = {\n",
    "    'configurable' : {\n",
    "        'thread_id' : 'paper_summary'\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "query = 'nicednjsdud@gmail.com으로 Attention Is All You Need 논문을 요약해서 이메일 초안을 작성해주세요.'\n",
    "for chunk in graph.stream({'messages': [HumanMessage(query)], 'summary': ''}, config = config, stream_mode='values') :\n",
    "    chunk['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='I couldn\\'t find the specific summary for the \"Attention Is All You Need\" paper. However, I can provide a general summary based on my knowledge:\\n\\nThe \"Attention Is All You Need\" paper introduces the Transformer model, which is a novel architecture for sequence transduction tasks. The key innovation of the Transformer is the use of self-attention mechanisms, which allow the model to weigh the importance of different words in a sentence when encoding and decoding sequences. This approach eliminates the need for recurrent layers, making the model more parallelizable and efficient. The Transformer has been highly influential, leading to significant advancements in natural language processing tasks.\\n\\nNow, I will create an email draft with this summary.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 273, 'prompt_tokens': 2020, 'total_tokens': 2293, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1408}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_fa7f5b168b', 'id': 'chatcmpl-D51i51Cfjl1m9QzE3tvwRiYW1zUeu', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c219e-d75c-7c93-93c6-ec905ef7caca-0', tool_calls=[{'name': 'create_gmail_draft', 'args': {'message': 'The \"Attention Is All You Need\" paper introduces the Transformer model, which is a novel architecture for sequence transduction tasks. The key innovation of the Transformer is the use of self-attention mechanisms, which allow the model to weigh the importance of different words in a sentence when encoding and decoding sequences. This approach eliminates the need for recurrent layers, making the model more parallelizable and efficient. The Transformer has been highly influential, leading to significant advancements in natural language processing tasks.', 'to': ['nicednjsdud@gmail.com'], 'subject': \"Summary of 'Attention Is All You Need' Paper\"}, 'id': 'call_ncuaYx3BfAvzBU0uQKdMTjpl', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 2020, 'output_tokens': 273, 'total_tokens': 2293, 'input_token_details': {'audio': 0, 'cache_read': 1408}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='Draft created. Draft Id: r-5053400065641278795', name='create_gmail_draft', id='ddc52fbb-cca6-4435-98dc-7569d24090fc', tool_call_id='call_ncuaYx3BfAvzBU0uQKdMTjpl'),\n",
       " AIMessage(content='I have created an email draft summarizing the \"Attention Is All You Need\" paper. You can find it in your drafts folder with the subject \"Summary of \\'Attention Is All You Need\\' Paper.\"', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 2322, 'total_tokens': 2364, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2176}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_fa7f5b168b', 'id': 'chatcmpl-D51iBgVkiFGyVC4vRZL9eZREKUCyh', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c219e-ef2b-7d01-ae9c-684cb6c1122d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 2322, 'output_tokens': 42, 'total_tokens': 2364, 'input_token_details': {'audio': 0, 'cache_read': 2176}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_message_list = graph.get_state(config).values['messages']\n",
    "current_message_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I couldn\\'t find the specific summary for the \"Attention Is All You Need\" paper. However, I can provide a general summary based on my knowledge:\\n\\nThe \"Attention Is All You Need\" paper introduces the Transformer model, which is a novel architecture for sequence transduction tasks. The key innovation of the Transformer is the use of self-attention mechanisms, which allow the model to weigh the importance of different words in a sentence when encoding and decoding sequences. This approach eliminates the need for recurrent layers, making the model more parallelizable and efficient. The Transformer has been highly influential, leading to significant advancements in natural language processing tasks.\\n\\nNow, I will create an email draft with this summary.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for index, message in enumerate(current_message_list):\n",
    "#     if index < len(current_message_list) - 1:\n",
    "#         graph.update_state(config, {'messages': RemoveMessage(id = message.id)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "논문의 출처 url를 첨부해주세요.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The \"Attention Is All You Need\" paper can be accessed on arXiv at the following URL: [https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762).\n",
      "\n",
      "I will update the email draft to include this URL.\n",
      "Tool Calls:\n",
      "  create_gmail_draft (call_Gv7bNEcmyULDQvXNRO6PP3DH)\n",
      " Call ID: call_Gv7bNEcmyULDQvXNRO6PP3DH\n",
      "  Args:\n",
      "    message: The \"Attention Is All You Need\" paper introduces the Transformer model, which is a novel architecture for sequence transduction tasks. The key innovation of the Transformer is the use of self-attention mechanisms, which allow the model to weigh the importance of different words in a sentence when encoding and decoding sequences. This approach eliminates the need for recurrent layers, making the model more parallelizable and efficient. The Transformer has been highly influential, leading to significant advancements in natural language processing tasks.\n",
      "\n",
      "You can access the paper at the following URL: [https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762).\n",
      "    to: ['nicednjsdud@gmail.com']\n",
      "    subject: Summary of 'Attention Is All You Need' Paper with URL\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: create_gmail_draft\n",
      "\n",
      "Draft created. Draft Id: r-4707960322076231673\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I have updated the email draft to include the URL for the \"Attention Is All You Need\" paper. You can find the updated draft in your drafts folder with the subject \"Summary of 'Attention Is All You Need' Paper with URL.\"\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I have updated the email draft to include the URL for the \"Attention Is All You Need\" paper. You can find the updated draft in your drafts folder with the subject \"Summary of 'Attention Is All You Need' Paper with URL.\"\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I have updated the email draft to include the URL for the \"Attention Is All You Need\" paper. You can find the updated draft in your drafts folder with the subject \"Summary of 'Attention Is All You Need' Paper with URL.\"\n"
     ]
    }
   ],
   "source": [
    "update_query = '논문의 출처 url를 첨부해주세요.'\n",
    "for chunk in graph.stream({'messages': [HumanMessage(update_query)]}, config = config, stream_mode='values') :\n",
    "    chunk['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_query = '초안이 좋습니다. 한글로 번역해서 이메일로 전송해주세요.'\n",
    "for chunk in graph.stream({'messages': [HumanMessage(update_query)]}, config = config, stream_mode='values') :\n",
    "    chunk['messages'][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
