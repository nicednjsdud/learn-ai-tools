
## 주요 기호와 읽는 방법
$$
y : 실제 값
$$
$$
\hat{y} : 예측값
$$

$$
\bar{y} : 평균값
$$

$$
Σ : 기호 이름은 '시그마'라고 하며, 보통 summation 이라고 함 (또는 합계 라고 함)
$$
 

## 함수

### 1차 함수

$$
y = ax + b => f(x)
$$

* 학교에서 익힌 표현 : f(x) = ax + b, **a는 기울기, b는 절편이라고도 함.**
* 딥러닝에서 사용하는 표현 : f(x) = wx + b, **w는 가중치(weight), b는 편향 (bias)**
    * weight, bias 라는 표현을 더 많이 사용함
    * w가 변하면, 그래프 기울기가 변함
    * b가 변하면, 그래프 높낮이가 변함

### 2차 함수

$$
f(x) = x^2
$$

## 미분

* 미분은 그래프의 한 점에서의 기울기 (gradient, 순간 변화량)을 의미
* 상미분 : f(x) 에는 변수가 x만 존재할때, f(x) 함수를 x로 미분하는 경우를 의미함 **(변수가 하나 존재할 경우)**
* 편미분 : 함수 안에 여러개의 변수가 존재할 때, 미분하는 경우를 의미함.

