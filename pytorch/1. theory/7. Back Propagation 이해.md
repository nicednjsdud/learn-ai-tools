
# Back Propagation (오차 역전파) 이해

## 다중 퍼셉트론의 또다른 이슈와 해결 방안 : 오차 역전파

* XOR 문제와 비선형적 문제는 다층 퍼셉트론의 은닉층 추가와 비선형 함수 추가로 해결
* 최적화를 위해, 결국 최종 예측값과 실제값과의 차이인 Loss 값을 최소로 해야 하며, 이를 위해,
* 은닉층을 포함한 모든 가중치 업데이트 필요

* 오차 역전파 개념1: 각 가중치값을 한번에 최적의 값으로 구하기 어려우므로 Gradient Descent로 적용

* 이를 오차 역전파(back propagation)라고 함

  * Gradient Descent

    * $\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 = cost(w, b) = Loss$

* 단순화해서 생각해보기

  * $(y - \hat{y})^2 = cost(w) = Loss$
  * $w := w - \alpha \frac{\partial}{\partial w} cost(w)$ 가 핵심이므로, $w$를 기반으로 단순화해보기
  * 다층 퍼셉트론을 단순화해서, 다음과 같이 하나의 은닉층과 하나의 입력만 있다고 가정해보면,

    * Gradient Descent를 통해, 결국 해야하는 일은, $Loss$를 $w_1, w_0$으로 편미분한 값을 구하는 것임

      * $w_1 := w_1 - \alpha \frac{\partial }{\partial w_1}Loss$
      * $w_0 := w_0 - \alpha \frac{\partial }{\partial w_0}Loss$

* Chain Rule (체인룰 또는 연쇄 법칙)

  * 합성함수의 미분법을 의미함

    * $f(g(x)) = f'(g(x)) * g'(x)$
    * 라이프니츠 표기법으로는 $y = f(u), u = g(x)$ 일때,
    * $\frac{dy}{dx} = \frac{dy}{du} * \frac{du}{dx}$
  
  * 다중 퍼셉트론의 각 은닉층의 가중치는 Gradient Descent 와 Chain Rule을 통해, 업데이트 가능 (이것이 오차 역전파 기법)

* 다중 퍼셉트론의 오차 역전파 (back propagation)

  * Gradient Descent를 통해, 결국 해야하는 일은, $Loss$를 $w_1, w_0$으로 편미분한 값을 구하는 것임

    * $w_1 := w_1 - \alpha \frac{\partial }{\partial w_1}Loss$
    * $w_0 := w_0 - \alpha \frac{\partial }{\partial w_0}Loss$

  * 즉, 각 레이어의 모든 가중치에 대해, $Loss$값에 대한 편미분값을 구하는 것이 핵심임

* 여러 레이어일 때를 계산한다면, 매 레이어 마다, 두 식만 계산하고, 나머지는 기존 식에서 계산된 값을 사용하면 됨

  