# Momentum Optimizer

## 주요 Optimizer

* 딥러닝의 학습은 결국 손실값이 가장 작은 모델을 만드는 것임
* 즉, 학습은 손실함수(loss function) 최소값을 찾아가는 과정이고, 이과정을 optimization (최적화) 이라고 함

  * 최적화를 수행하는 알고리즘을 Optimizer이라고 함

* 대표적인 Optimizer가 Gradient Descent (경사 하강법)를 기반으로 한 SGD 이며,
* 이외에 더 개선된 다양한 Optimizer가 제안되고, 사용되고 있음

## Momentum

* Momentum은 SGD에 관성(momentum)이 추가된 Optimizer 임
* 관성(momentum) 적용을 위해, velocity term $(u)$ 이 추가됨