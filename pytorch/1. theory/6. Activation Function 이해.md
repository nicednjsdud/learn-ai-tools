
# Activation Function 이해

## activation function 과 non-linear function

* 세상의 다양한 문제는 non-linear(비선형) 문제가 더 많음
* 다층 퍼셉트론에서 activation function 으로 non-linear function을 사용하여, non-linear(비선형) 문제를 보다 잘 모사할 수 있도록 구성
* 예 : 입력측잉 $x_0 * w_o + b_0$ 값이 들어가고,

  * 다시 이를 은닉층에서, 출력층으로 ($x_0 * w_0 + b_0$) $ * w_1 + b_1$과 같이 계산한다면, 결국 일차식으로 선형으로 모사할 수 있음
  * 입력층에서, 출력층으로 계산하는 과정에서, non-linear function을 적용하여, non-linear(비선형)문제로 모사할 수 있도록 함

* 참고 : network capacity

  * depth와 width를 넓게 할수록, 딥러닝은 보다 복잡한 형태의 문제를 모사할 수 있다.
  * 참고 : 초거대 AI

    * depth와 width를 획기적으로 키우고, 이를 학습시키기 위해 데이터도 획기적으로 큰 데이터를 사용하여 학습시킨 AI
    * 예 : 구글 PaLM (Pathways Language Model)