
# Sigmoid

## Sigmoid 함수 이해

* sigmoid 함수는 머신러닝의 주요 모델 중 하나인 logistic regression 모델에서 많이 사용
* logistic regression은 이름에 Regression이 들어 있지만, 분류 모델임

* Logistic Regression 은 Linear Classification 과 달리 "S"자 모양으로 곡선으로 계산하는 시그모이드 함수를 사용해서, **분류**를 하는 모델

  * 현실 세계에서 특정 현상은 특정 변수에 대한 확률값이 선형이 아닌 S-커브 형태를 따르는 경우가 많기 때문에,
  * 이를 표현한 것이 로지스틱에서 사용되는 "S"자 모양의 시그모이드 함수임

* 참 또는 거짓과 같이, 이진 분류를 하는 예측에는 Linear Classification이 예측 결과를 잘 나타내는 쉭을 만들기 어려움

  * 마이너스 확률이 나오고, 예측 결과에 잘 매칭되기 어려움

* 로지스틱 회귀는 정확히 0 또는 1을 예측하는 대신 확률(0과 1사이의 값)을 생성하여 0과 1을 분류하는 예측 모델
* 결과값을 0과 1사이의 값으로 조정하여 반환

  * 0 ~ 100%의 적절한 확률값을 가질 수 있고, 예측 결과과 선형회귀 모델보다 잘 매칭됨

## 자연상수(e) 이해를 위한 로그와 로그함수

* 자연대수 오일러 상수 라고도 불리움 (이외에도 자연로그의 밑, 네이피어 상수라고도 불림)
* 로그(log)정리

  * a와 b를 알고 있을 때, 이를 기반으로 $x$를 구하기 위해 사용하는 수학 기법이 로그(log)임
  * $a^x = b$
  * 양변에 로그(log)를 취해주면 다음과 같음

    * $log_ab = x$
    * 이 때 $a$를 밑이라고 이야기하며, b를 진수라고 함
    * $b > 0, a > 0, a != 1$  조건이어야 함

* $e$는 오일러 수(Euler's Number)라고도 불리고, 실제 값은 약 2.71828.. 정도의 값을 가짐
* 자연계의 현상을 잘 설명한다고 해서 **자연상수**라고 불리며, $e$를 밑으로 하는 로그을 **자연로그**라고 하며 $ln$으로 표기함
* $ln x = log_ex$
