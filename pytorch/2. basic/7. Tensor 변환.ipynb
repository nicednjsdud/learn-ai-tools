{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshape() : 배열 구조 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1: tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], dtype=torch.float64) torch.Size([2, 3])\n",
      "reshaped data1: tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]], dtype=torch.float64) torch.Size([3, 2])\n",
      "reshaped data1 with -1: tensor([[1., 2., 3., 4., 5., 6.]], dtype=torch.float64) torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "data1 = torch.DoubleTensor([[1,2,3],[4,5,6]])\n",
    "print(\"data1:\", data1, data1.shape)\n",
    "data1 = data1.reshape(3,2)\n",
    "print(\"reshaped data1:\", data1, data1.shape)\n",
    "data1 = data1.reshape(1, -1) # -1은 열을 행의 갯수에 맞춰 자동 계산\n",
    "print(\"reshaped data1 with -1:\", data1, data1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### view() : 텐서 구조 변경\n",
    "\n",
    "* pytorch 에서는 numpy 처럼 reshape()로 배열 구조를 변경할 수 있지만, reshape()보다 view() 메서드를 많이 사용함\n",
    "* view() 메서드는 reshape()와 사용법은 동일\n",
    "\n",
    "* 원소 수를 유지하면서 텐서의 크기를 변경할 때 많이 사용하며, 매우 중요함\n",
    "\n",
    "* **높이, 너비, 깊이** 순서로 기억하는 편이 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data2: tensor([[[ 1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.]],\n",
      "\n",
      "        [[ 7.,  8.,  9.],\n",
      "         [10., 11., 12.]]], dtype=torch.float64) torch.Size([2, 2, 3])\n",
      "data2 height(k): 2\n",
      "data2 width(n): 2\n",
      "data2 depth(m): 3\n"
     ]
    }
   ],
   "source": [
    "data2 = torch.DoubleTensor([\n",
    "  [[1,2,3],\n",
    "   [4,5,6]],\n",
    "   [[7,8,9], \n",
    "   [10,11,12]],\n",
    "])\n",
    "\n",
    "print(\"data2:\", data2, data2.shape)\n",
    "print(\"data2 height(k):\", data2.size(0))  # 첫번째 차원의 크기\n",
    "print(\"data2 width(n):\", data2.size(1))   # 두번째 차원의 크기\n",
    "print(\"data2 depth(m):\", data2.size(2))   # 세번째 차원의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshaped data2 with -1: tensor([[ 1.,  2.,  3.,  4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9., 10., 11., 12.]], dtype=torch.float64) torch.Size([2, 6])\n",
      "reshaped data2 with -1: tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]], dtype=torch.float64) torch.Size([4, 3])\n",
      "reshaped data2 with -1: tensor([[[ 1.,  2.],\n",
      "         [ 3.,  4.]],\n",
      "\n",
      "        [[ 5.,  6.],\n",
      "         [ 7.,  8.]],\n",
      "\n",
      "        [[ 9., 10.],\n",
      "         [11., 12.]]], dtype=torch.float64) torch.Size([3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "data2 = data2.view(2, -1) # (2, ?)으로 구성, -1은 자동 계산, (2, 2x3)이 됨\n",
    "print(\"reshaped data2 with -1:\", data2, data2.shape)\n",
    "\n",
    "data2 = data2.view(-1, 3) # (?, 3)으로 구성, -1은 자동 계산, (4, 3)이 됨\n",
    "print(\"reshaped data2 with -1:\", data2, data2.shape)\n",
    "\n",
    "data2 = data2.view(3, 2, -1) # (3, 2, ?)으로 구성, -1은 자동 계산, (3, 2, 2)가 됨\n",
    "print(\"reshaped data2 with -1:\", data2, data2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### squeeze() : 텐서 차원 압축\n",
    "\n",
    "* 차원이 1인 경우, 해당 차원을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data3: tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]]) 2 torch.Size([3, 1])\n",
      "data4 (squeezed data3): tensor([1., 2., 3.]) 1 torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "data3 = torch.FloatTensor([ [1], [2], [3] ])\n",
    "data4 = data3.squeeze()  # 차원 축소\n",
    "\n",
    "print(\"data3:\", data3, data3.dim(), data3.shape)\n",
    "print(\"data4 (squeezed data3):\", data4, data4.dim(), data4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unsqueeze() : 특정 위치에 1인 차원을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data5: tensor([1., 2., 3.]) 1 torch.Size([3])\n",
      "data5_5 (unsqueezed data5 at dim 0): tensor([[1., 2., 3.]]) 2 torch.Size([1, 3])\n",
      "data6 (unsqueezed data5): tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]]) 2 torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "data5 = torch.FloatTensor([1,2,3])\n",
    "data5_5 = data5.unsqueeze(0)  # 차원 확장\n",
    "data6 = data5.unsqueeze(1)  # 차원 확장\n",
    "\n",
    "print(\"data5:\", data5, data5.dim(), data5.shape)\n",
    "print(\"data5_5 (unsqueezed data5 at dim 0):\", data5_5, data5_5.dim(), data5_5.shape)\n",
    "print(\"data6 (unsqueezed data5):\", data6, data6.dim(), data6.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
